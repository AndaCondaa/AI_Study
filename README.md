####[ML 정리](docs/ML.md)

####[DL 정리](docs/DL.md)

# Computer Vision

<br>

## 이미지 분류

대부분의 합성곱 네트워크는 특징맵의 크기를 줄이면서 차원 수를 증가시키는 구조

LeNet , AlexNet, VGG, GoogLeNet, ResNet

#### LeNet

- 활성화 함수로 출력층에서 시그모이드, 나머지 계층에서 하이퍼볼릭 탄젠트 사용

#### AlexNet

- 최대값 풀링, ReLU
- LeNet과의 중요한 차이
  - ReLU 사용 -> 기울기 소실 문제 X, 기울기 소실 문제는 계층을 깊게 쌓을 수 없게 만들기 때문에 중요함
  - 드롭아웃 추가 -> 과대적합 완화

#### VGG

- AlexNet이 11x11, 5x5, 3x3의 큰 커널을 사용한 것과 달리, 3x3의 작은 커널만을 사용하여 Local Features 학습에도 좋고 비선형성을 더 많이 확보

#### ResNet

- 기본 블록에서는 3x3 2개 계층을 블록으로 해서 잔차연결
- 병목 블록에서는 1x1, 3x3, 1x1 게층을 묶어서 블록화, 연상량 감소, ResNet-50, 101, 152에서 사용
