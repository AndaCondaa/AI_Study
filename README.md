# DL 정리

## Loss Function

- 신경망은 결국 Loss Function을 가지고 손실이 최소가 되는 매개변수, 즉 가중치를 찾는 과정

- <b>특정 매개변수일 때,  정해지는 손실함수의 미분에 집중</b>❗️

- 정확도를 지표로 삼으면, 거의 모든 곳에서 미분값이 0이기 때문에 학습에 사용할 수 없음, 즉 손실함수의 미분가능 연속성때문에 사용함 (활성화함수로 계단함수를 생각)

- 종류
  - 오차제곱합(SSE)
    - $E =\frac{1}{2} \sum(y_k-t_k)^2$
    - 분류 문제일 경우?
      - 모든 타겟(타겟종류)에 대한 Sigmoid 또는 Softmax 값을 가지고 적용하기 때문에 분류에서는 잘 사용 ❌
  - Cross Entropy Error (CEE)
    - $E = - \sum t_k\log y_k$
    - 분류에서 원핫인코딩 된 경우, 정답값이 아닌 레이블은 $t_k$가 0이 되므로, 정답 레이블로 추정한 확률로 확인하는 개념

