{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe681259",
   "metadata": {},
   "source": [
    "### 배치 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ee7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([[-0.9793, -0.7078, -0.7073],\n",
      "        [ 1.3732,  1.4142,  1.4142],\n",
      "        [-0.3939, -0.7064, -0.7069]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "x = torch.FloatTensor(\n",
    "    [\n",
    "        [-0.23, 1.23, 0.23],\n",
    "        [93.123, 1230, 23892],\n",
    "        [23, 2, 4]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(x.dim())\n",
    "print(nn.BatchNorm1d(3)(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef8182b",
   "metadata": {},
   "source": [
    "### 가중치 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c135b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.layer[0].weight)\n",
    "        self.layer[0].bias.data.fill_(0.01)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.fc.bias.data.fill_(0.01)\n",
    "        \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc16715",
   "metadata": {},
   "source": [
    "### 가중치 초기화 함수 모듈화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6553cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply: Linear(in_features=1, out_features=2, bias=True)\n",
      "Apply: Sigmoid()\n",
      "Apply: Sequential(\n",
      "  (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n",
      "Apply: Linear(in_features=2, out_features=1, bias=True)\n",
      "Apply: Net(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0.01)\n",
    "        print(f\"Apply: {module}\")\n",
    "        \n",
    "model = Net()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04e0c8",
   "metadata": {},
   "source": [
    "### NLPAUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c1958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src : I'm boy.\n",
      "dst : i ' l m my boy.\n",
      "=======================\n",
      "src : We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dst : we can mostly only see some a short distance straight ahead, sometimes but soon we can see some plenty there that needs to be well done.\n",
      "=======================\n",
      "src : If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dst : conversely if a turing machine is expected otherwise to usually be extremely infallible, it cannot also be incredibly intelligent.\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "texts = [\n",
    "    \"I'm boy.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = naw.ContextualWordEmbsAug(model_path=\"bert-base-uncased\", action=\"insert\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280167d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src : I'm good boy.\n",
      "dst : I ' m go boy.\n",
      "=======================\n",
      "src : We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dst : We can ny see a srt istnc aad, but we can see plen there at needs to be do.\n",
      "=======================\n",
      "src : If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dst : If a machine is exped to be nflible, it cnno so be nelient.\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as naw\n",
    "\n",
    "texts = [\n",
    "    \"I'm good boy.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = naw.RandomCharAug(action=\"delete\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1272768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src : I'm good boy.\n",
      "dst : I m ' boy good.\n",
      "=======================\n",
      "src : We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dst : We can see only a short distance ahead, but we can plenty see there that needs to done be.\n",
      "=======================\n",
      "src : If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dst : A is if expected machine to infallible be, it cannot also be intelligent.\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "texts = [\n",
    "    \"I'm good boy.\",\n",
    "    \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\",\n",
    "    \"If a machine is expected to be infallible, it cannot also be intelligent.\",\n",
    "]\n",
    "\n",
    "aug = naw.RandomWordAug(action=\"swap\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71adec75",
   "metadata": {},
   "source": [
    "### 이미지 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d8e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "torch.Size([3, 512, 512])\n",
      "tensor([[[0.6745, 0.6706, 0.6667,  ..., 0.1922, 0.1961, 0.1922],\n",
      "         [0.6863, 0.6784, 0.6667,  ..., 0.1922, 0.1922, 0.1882],\n",
      "         [0.6863, 0.6784, 0.6706,  ..., 0.1922, 0.1922, 0.1882],\n",
      "         ...,\n",
      "         [0.4667, 0.4588, 0.4549,  ..., 0.2196, 0.2118, 0.1961],\n",
      "         [0.4745, 0.4667, 0.4627,  ..., 0.2157, 0.2000, 0.1922],\n",
      "         [0.4784, 0.4706, 0.4706,  ..., 0.2118, 0.2000, 0.1961]],\n",
      "\n",
      "        [[0.8235, 0.8196, 0.8157,  ..., 0.1961, 0.2000, 0.1961],\n",
      "         [0.8353, 0.8275, 0.8157,  ..., 0.1961, 0.1961, 0.1922],\n",
      "         [0.8392, 0.8314, 0.8196,  ..., 0.1961, 0.1961, 0.1922],\n",
      "         ...,\n",
      "         [0.6353, 0.6275, 0.6157,  ..., 0.2745, 0.2706, 0.2588],\n",
      "         [0.6471, 0.6392, 0.6275,  ..., 0.2667, 0.2588, 0.2549],\n",
      "         [0.6549, 0.6431, 0.6314,  ..., 0.2667, 0.2549, 0.2588]],\n",
      "\n",
      "        [[0.9647, 0.9647, 0.9647,  ..., 0.1647, 0.1686, 0.1647],\n",
      "         [0.9765, 0.9686, 0.9608,  ..., 0.1647, 0.1647, 0.1608],\n",
      "         [0.9725, 0.9647, 0.9647,  ..., 0.1647, 0.1647, 0.1608],\n",
      "         ...,\n",
      "         [0.7765, 0.7647, 0.7569,  ..., 0.2039, 0.1961, 0.1843],\n",
      "         [0.7843, 0.7765, 0.7647,  ..., 0.1961, 0.1882, 0.1882],\n",
      "         [0.7882, 0.7804, 0.7686,  ..., 0.1961, 0.1882, 0.1882]]])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512,512)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"./datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "\n",
    "\n",
    "print(transformed_image.shape)\n",
    "print(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29b32c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(degrees=30, expand=False, center=None),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"./datasets/images/cat.jpg\")\n",
    "transform(image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cf80404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(size=(512,512)),\n",
    "        transforms.Pad(padding=50, fill=(127,127,255), padding_mode=\"symmetric\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"./datasets/images/cat.jpg\")\n",
    "transform(image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb17428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0, translate=(0.0, 0.0),\n",
    "            scale=(1.2, 1.2), shear=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"./datasets/images/cat.jpg\")\n",
    "transform(image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20877887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4c507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbc2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ef706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ae664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4ca27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05117002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527c4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50738bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f80cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
