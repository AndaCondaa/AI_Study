{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fc0240",
   "metadata": {},
   "source": [
    "### 텐서 생성\n",
    "tensor() 메소드는 입력받은 데이터의 자료형을 그대로 사용 비추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98445d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([1,2,3]))                        # 입력 자료형 그대로 만듦\n",
    "print(torch.Tensor([[1,2,3], [4,5,6]]))             # 기본 Float\n",
    "print(torch.LongTensor([1,2,3]))\n",
    "print(torch.FloatTensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d71ed",
   "metadata": {},
   "source": [
    "### 텐서 속성\n",
    "shape, dtype, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf3019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8631, 0.4983]])\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand(1, 2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabab93d",
   "metadata": {},
   "source": [
    "### 텐서 차원 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6adfa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4688, 0.5552]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.4688],\n",
      "        [0.5552]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand(1, 2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "#tensor = torch.reshape(tensor, (2, 1))\n",
    "tensor = tensor.reshape(2, 1)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf799854",
   "metadata": {},
   "source": [
    "### 자료형 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6bd115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9212, 0.6410, 0.8986],\n",
      "        [0.9082, 0.3878, 0.1290],\n",
      "        [0.2852, 0.3037, 0.5846]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand((3, 3), dtype=torch.float)          ## 자료형 설정 시, 그냥 float이 아닌, torch.* 형태로 설정\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df44e1",
   "metadata": {},
   "source": [
    "### 장치 설정 (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f0c57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='mps:0')\n",
      "tensor([[0.3386]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = torch.FloatTensor([1, 2, 3]).to(device)\n",
    "tensor = torch.rand((1, 1), device=device)\n",
    "\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa252c9",
   "metadata": {},
   "source": [
    "### 장치 변환\n",
    "- cpu 텐서와 gpu 텐서 연산 불가\n",
    "- gpu 텐서와 넘파이 배열 연산 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76f6f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='mps:0')\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "cpu = torch.FloatTensor([1,2,3])\n",
    "gpu = cpu.to(\"mps\")\n",
    "gpu2cpu = gpu.to(\"cpu\")\n",
    "\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(gpu2cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7432f63",
   "metadata": {},
   "source": [
    "### Numpy to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "ndarray = np.array([1, 2, 3], dtype=np.uint8)\n",
    "print(torch.tensor(ndarray))\n",
    "print(torch.Tensor(ndarray))\n",
    "print(torch.from_numpy(ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61314e2",
   "metadata": {},
   "source": [
    "### Tensor to Numpy\n",
    "- Tensor는 모든 연산을 추적해 기록함 (역전파 등과 같은 연산이 진행돼 모델 학습을 진행하기 위함)\n",
    "- detach() 메소드로 새로운 텐서를 반환하여 numpy()로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce119457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.FloatTensor([1, 2, 3]).to(\"mps\")\n",
    "ndarray = tensor.detach().cpu().numpy()\n",
    "print(ndarray)\n",
    "print(type(ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814473bf",
   "metadata": {},
   "source": [
    "### Simple Linear Regression (Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c7694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, weight : 5.313, bias : 0.295, cost : 1.346\n",
      "epoch : 2000, weight : 5.312, bias : 0.315, cost : 1.345\n",
      "epoch : 3000, weight : 5.311, bias : 0.329, cost : 1.345\n",
      "epoch : 4000, weight : 5.310, bias : 0.341, cost : 1.345\n",
      "epoch : 5000, weight : 5.310, bias : 0.350, cost : 1.345\n",
      "epoch : 6000, weight : 5.310, bias : 0.356, cost : 1.344\n",
      "epoch : 7000, weight : 5.309, bias : 0.361, cost : 1.344\n",
      "epoch : 8000, weight : 5.309, bias : 0.365, cost : 1.344\n",
      "epoch : 9000, weight : 5.309, bias : 0.369, cost : 1.344\n",
      "epoch : 10000, weight : 5.309, bias : 0.371, cost : 1.344\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make Dataset\n",
    "x = np.empty((0, 1))\n",
    "y = np.empty((0, 1))\n",
    "temp_w = 5.3122\n",
    "\n",
    "for i in range(30):\n",
    "    value = np.random.uniform(-2, 2)\n",
    "    x = np.append(x, [[i]], axis=0)\n",
    "    y = np.append(y, [[temp_w*i + value]], axis=0)\n",
    "    \n",
    "# Set initial parameters\n",
    "weight = 0.0\n",
    "bias = 0.0\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Train\n",
    "for epoch in range(10000):\n",
    "    y_hat = weight * x + bias\n",
    "    cost = ((y - y_hat) ** 2).mean()\n",
    "\n",
    "    weight = weight - learning_rate * ((y_hat - y) * x).mean()\n",
    "    bias = bias - learning_rate * (y_hat - y).mean()\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, weight : {weight:.3f}, bias : {bias:.3f}, cost : {cost:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9075f58",
   "metadata": {},
   "source": [
    "### Simple Linear Regression (Pytorch)\n",
    "- 가중치, 편향 텐서에서 requires_grad는 자동 미분 기능을 의미함\n",
    "- zero_grad() -> backward() -> step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, weight : 5.306, bias : 0.391, cost : 0.877\n",
      "epoch : 2000, weight : 5.302, bias : 0.463, cost : 0.872\n",
      "epoch : 3000, weight : 5.300, bias : 0.505, cost : 0.870\n",
      "epoch : 4000, weight : 5.299, bias : 0.530, cost : 0.870\n",
      "epoch : 5000, weight : 5.298, bias : 0.545, cost : 0.869\n",
      "epoch : 6000, weight : 5.298, bias : 0.554, cost : 0.869\n",
      "epoch : 7000, weight : 5.297, bias : 0.559, cost : 0.869\n",
      "epoch : 8000, weight : 5.297, bias : 0.562, cost : 0.869\n",
      "epoch : 9000, weight : 5.297, bias : 0.564, cost : 0.869\n",
      "epoch : 10000, weight : 5.297, bias : 0.565, cost : 0.869\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim     # 최적함 함수 포함\n",
    "\n",
    "# Make Dataset\n",
    "x = np.empty((0, 1))\n",
    "y = np.empty((0, 1))\n",
    "temp_w = 5.3122\n",
    "\n",
    "for i in range(30):\n",
    "    value = np.random.uniform(-2, 2)\n",
    "    x = np.append(x, [[i]], axis=0)\n",
    "    y = np.append(y, [[temp_w*i + value]], axis=0)\n",
    "\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.FloatTensor(y)\n",
    "\n",
    "# Set initial parameters\n",
    "weight = torch.zeros(1, requires_grad=True)\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optim.SGD([weight, bias], lr=learning_rate)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    hypotesis = x * weight + bias\n",
    "    cost = torch.mean((hypotesis - y) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, weight : {weight.item():.3f}, bias : {bias.item():.3f}, cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "107b9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, model : [Parameter containing:\n",
      "tensor([[5.2757]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0921], requires_grad=True)], cost : 1.127\n",
      "epoch : 2000, model : [Parameter containing:\n",
      "tensor([[5.2683]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2390], requires_grad=True)], cost : 1.105\n",
      "epoch : 3000, model : [Parameter containing:\n",
      "tensor([[5.2638]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3260], requires_grad=True)], cost : 1.097\n",
      "epoch : 4000, model : [Parameter containing:\n",
      "tensor([[5.2612]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3775], requires_grad=True)], cost : 1.095\n",
      "epoch : 5000, model : [Parameter containing:\n",
      "tensor([[5.2597]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4080], requires_grad=True)], cost : 1.094\n",
      "epoch : 6000, model : [Parameter containing:\n",
      "tensor([[5.2587]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4260], requires_grad=True)], cost : 1.093\n",
      "epoch : 7000, model : [Parameter containing:\n",
      "tensor([[5.2582]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4367], requires_grad=True)], cost : 1.093\n",
      "epoch : 8000, model : [Parameter containing:\n",
      "tensor([[5.2579]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4431], requires_grad=True)], cost : 1.093\n",
      "epoch : 9000, model : [Parameter containing:\n",
      "tensor([[5.2577]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4468], requires_grad=True)], cost : 1.093\n",
      "epoch : 10000, model : [Parameter containing:\n",
      "tensor([[5.2576]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4490], requires_grad=True)], cost : 1.093\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "\n",
    "# Make Dataset\n",
    "x = np.empty((0, 1))\n",
    "y = np.empty((0, 1))\n",
    "temp_w = 5.3122\n",
    "\n",
    "for i in range(30):\n",
    "    value = np.random.uniform(-2, 2)\n",
    "    x = np.append(x, [[i]], axis=0)\n",
    "    y = np.append(y, [[temp_w*i + value]], axis=0)\n",
    "\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.FloatTensor(y)\n",
    "\n",
    "# Set initial parameters\n",
    "model = nn.Linear(1, 1, bias=True)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    output = model(x)\n",
    "    cost = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, model : {list(model.parameters())}, cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5591668",
   "metadata": {},
   "source": [
    "### DataSet, DataLoader\n",
    "- drop_last : 불완전한 배치의 사용 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "29b6ec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, model : [Parameter containing:\n",
      "tensor([[ 0.8158, -0.0464],\n",
      "        [ 0.2666,  0.9545]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2032, -0.4224], requires_grad=True)], cost : 0.040\n",
      "epoch : 2000, model : [Parameter containing:\n",
      "tensor([[ 0.9485, -0.1151],\n",
      "        [ 0.3467,  0.9131]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4045, -0.5439], requires_grad=True)], cost : 0.010\n",
      "epoch : 3000, model : [Parameter containing:\n",
      "tensor([[ 1.0161, -0.1501],\n",
      "        [ 0.3875,  0.8920]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5071, -0.6058], requires_grad=True)], cost : 0.003\n",
      "epoch : 4000, model : [Parameter containing:\n",
      "tensor([[ 1.0506, -0.1679],\n",
      "        [ 0.4083,  0.8813]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5594, -0.6373], requires_grad=True)], cost : 0.001\n",
      "epoch : 5000, model : [Parameter containing:\n",
      "tensor([[ 1.0681, -0.1769],\n",
      "        [ 0.4189,  0.8758]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5860, -0.6534], requires_grad=True)], cost : 0.000\n",
      "epoch : 6000, model : [Parameter containing:\n",
      "tensor([[ 1.0771, -0.1816],\n",
      "        [ 0.4243,  0.8730]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5996, -0.6616], requires_grad=True)], cost : 0.000\n",
      "epoch : 7000, model : [Parameter containing:\n",
      "tensor([[ 1.0816, -0.1839],\n",
      "        [ 0.4270,  0.8716]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6065, -0.6658], requires_grad=True)], cost : 0.000\n",
      "epoch : 8000, model : [Parameter containing:\n",
      "tensor([[ 1.0839, -0.1851],\n",
      "        [ 0.4284,  0.8709]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6100, -0.6679], requires_grad=True)], cost : 0.000\n",
      "epoch : 9000, model : [Parameter containing:\n",
      "tensor([[ 1.0851, -0.1857],\n",
      "        [ 0.4292,  0.8705]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6118, -0.6690], requires_grad=True)], cost : 0.000\n",
      "epoch : 10000, model : [Parameter containing:\n",
      "tensor([[ 1.0857, -0.1860],\n",
      "        [ 0.4295,  0.8703]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6127, -0.6695], requires_grad=True)], cost : 0.000\n",
      "epoch : 11000, model : [Parameter containing:\n",
      "tensor([[ 1.0860, -0.1862],\n",
      "        [ 0.4297,  0.8702]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6132, -0.6698], requires_grad=True)], cost : 0.000\n",
      "epoch : 12000, model : [Parameter containing:\n",
      "tensor([[ 1.0862, -0.1863],\n",
      "        [ 0.4298,  0.8702]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6134, -0.6700], requires_grad=True)], cost : 0.000\n",
      "epoch : 13000, model : [Parameter containing:\n",
      "tensor([[ 1.0863, -0.1863],\n",
      "        [ 0.4298,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6135, -0.6700], requires_grad=True)], cost : 0.000\n",
      "epoch : 14000, model : [Parameter containing:\n",
      "tensor([[ 1.0863, -0.1863],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n",
      "epoch : 15000, model : [Parameter containing:\n",
      "tensor([[ 1.0863, -0.1863],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n",
      "epoch : 16000, model : [Parameter containing:\n",
      "tensor([[ 1.0864, -0.1864],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n",
      "epoch : 17000, model : [Parameter containing:\n",
      "tensor([[ 1.0864, -0.1864],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n",
      "epoch : 18000, model : [Parameter containing:\n",
      "tensor([[ 1.0864, -0.1864],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n",
      "epoch : 19000, model : [Parameter containing:\n",
      "tensor([[ 1.0864, -0.1864],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n",
      "epoch : 20000, model : [Parameter containing:\n",
      "tensor([[ 1.0864, -0.1864],\n",
      "        [ 0.4299,  0.8701]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6136, -0.6701], requires_grad=True)], cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_x = torch.FloatTensor([\n",
    "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
    "\n",
    "model = nn.Linear(2, 2, bias=True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "        \n",
    "    cost =  cost / len(train_dataloader)\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, model : {list(model.parameters())}, cost : {cost:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3293a",
   "metadata": {},
   "source": [
    "### 비선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f352e3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, model : [Parameter containing:\n",
      "tensor([[ 3.1125, -1.7006]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.2534], device='mps:0', requires_grad=True)], cost : 0.318\n",
      "epoch : 2000, model : [Parameter containing:\n",
      "tensor([[ 3.1113, -1.7027]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.1897], device='mps:0', requires_grad=True)], cost : 0.290\n",
      "epoch : 3000, model : [Parameter containing:\n",
      "tensor([[ 3.1103, -1.7025]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.1314], device='mps:0', requires_grad=True)], cost : 0.241\n",
      "epoch : 4000, model : [Parameter containing:\n",
      "tensor([[ 3.1091, -1.7025]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0781], device='mps:0', requires_grad=True)], cost : 0.215\n",
      "epoch : 5000, model : [Parameter containing:\n",
      "tensor([[ 3.1083, -1.7028]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0295], device='mps:0', requires_grad=True)], cost : 0.201\n",
      "epoch : 6000, model : [Parameter containing:\n",
      "tensor([[ 3.1080, -1.7030]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0149], device='mps:0', requires_grad=True)], cost : 0.158\n",
      "epoch : 7000, model : [Parameter containing:\n",
      "tensor([[ 3.1070, -1.7027]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0558], device='mps:0', requires_grad=True)], cost : 0.164\n",
      "epoch : 8000, model : [Parameter containing:\n",
      "tensor([[ 3.1065, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0931], device='mps:0', requires_grad=True)], cost : 0.148\n",
      "epoch : 9000, model : [Parameter containing:\n",
      "tensor([[ 3.1060, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1273], device='mps:0', requires_grad=True)], cost : 0.132\n",
      "epoch : 10000, model : [Parameter containing:\n",
      "tensor([[ 3.1053, -1.7031]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1584], device='mps:0', requires_grad=True)], cost : 0.133\n",
      "tensor([[  1.5607],\n",
      "        [ 69.2764],\n",
      "        [357.1700]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "train_dataset = CustomDataset(\"./datasets/non_linear.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, model : {list(model.parameters())}, cost : {cost:.3f}\")\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = torch.FloatTensor(\n",
    "        [\n",
    "            [1**2, 1],\n",
    "            [5**2, 5],\n",
    "            [11**2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "torch.save(\n",
    "    model,\n",
    "    \"./models/model.pt\"\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"./models/model_state_dict.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8cd555",
   "metadata": {},
   "source": [
    "### 데이터세트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4eec825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, model : [Parameter containing:\n",
      "tensor([[ 3.1000, -1.7007]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4929], device='mps:0', requires_grad=True)], cost : 0.074\n",
      "epoch : 2000, model : [Parameter containing:\n",
      "tensor([[ 3.1007, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4874], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "epoch : 3000, model : [Parameter containing:\n",
      "tensor([[ 3.1014, -1.7008]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4854], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "epoch : 4000, model : [Parameter containing:\n",
      "tensor([[ 3.1009, -1.7008]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4845], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 5000, model : [Parameter containing:\n",
      "tensor([[ 3.1012, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4842], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 6000, model : [Parameter containing:\n",
      "tensor([[ 3.1013, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4841], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 7000, model : [Parameter containing:\n",
      "tensor([[ 3.1016, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "epoch : 8000, model : [Parameter containing:\n",
      "tensor([[ 3.1011, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.074\n",
      "epoch : 9000, model : [Parameter containing:\n",
      "tensor([[ 3.1012, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 10000, model : [Parameter containing:\n",
      "tensor([[ 3.0999, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4839], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "tensor([[144.6720],\n",
      "        [204.9232],\n",
      "        [  0.3448],\n",
      "        [ 50.4866]], device='mps:0')\n",
      "tensor([[264.0887],\n",
      "        [ 28.6285],\n",
      "        [  4.1784],\n",
      "        [244.3778]], device='mps:0')\n",
      "tensor([[ 80.0691],\n",
      "        [173.4275],\n",
      "        [197.3720],\n",
      "        [132.2558]], device='mps:0')\n",
      "tensor([[  2.1093],\n",
      "        [ 75.4597],\n",
      "        [101.8738],\n",
      "        [146.7400]], device='mps:0')\n",
      "tensor([[109.0974],\n",
      "        [ 17.7261],\n",
      "        [164.2837],\n",
      "        [272.6621]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "dataset = CustomDataset(\"./datasets/non_linear.csv\")\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "val_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], torch.manual_seed(0))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, model : {list(model.parameters())}, cost : {cost:.3f}\")\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in val_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        print(outputs)\n",
    "        \n",
    "torch.save(\n",
    "    model,\n",
    "    \"./models/model.pt\"\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"./models/model_state_dict.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ff4bf",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ae07b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (layer): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "    \n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model = torch.load(\"./models/model.pt\", map_location=device, weights_only=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24050bb8",
   "metadata": {},
   "source": [
    "### 모델 상태 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "16838879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.8828],\n",
      "        [ 69.4762],\n",
      "        [356.8583]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "    \n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "\n",
    "model_state_dict = torch.load(\"./models/model_state_dict.pt\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = torch.FloatTensor(\n",
    "        [\n",
    "            [1**2, 1],\n",
    "            [5**2, 5],\n",
    "            [11**2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c962016",
   "metadata": {},
   "source": [
    "### 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "883da664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000, model : [Parameter containing:\n",
      "tensor([[ 3.1000, -1.7007]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4929], device='mps:0', requires_grad=True)], cost : 0.074\n",
      "epoch : 2000, model : [Parameter containing:\n",
      "tensor([[ 3.1007, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4874], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "epoch : 3000, model : [Parameter containing:\n",
      "tensor([[ 3.1014, -1.7008]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4854], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "epoch : 4000, model : [Parameter containing:\n",
      "tensor([[ 3.1009, -1.7008]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4845], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 5000, model : [Parameter containing:\n",
      "tensor([[ 3.1012, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4842], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 6000, model : [Parameter containing:\n",
      "tensor([[ 3.1013, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4841], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 7000, model : [Parameter containing:\n",
      "tensor([[ 3.1016, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "epoch : 8000, model : [Parameter containing:\n",
      "tensor([[ 3.1011, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.074\n",
      "epoch : 9000, model : [Parameter containing:\n",
      "tensor([[ 3.1012, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.072\n",
      "epoch : 10000, model : [Parameter containing:\n",
      "tensor([[ 3.0999, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4839], device='mps:0', requires_grad=True)], cost : 0.073\n",
      "tensor([[144.6720],\n",
      "        [204.9232],\n",
      "        [  0.3448],\n",
      "        [ 50.4866]], device='mps:0')\n",
      "tensor([[264.0887],\n",
      "        [ 28.6285],\n",
      "        [  4.1784],\n",
      "        [244.3778]], device='mps:0')\n",
      "tensor([[ 80.0691],\n",
      "        [173.4275],\n",
      "        [197.3720],\n",
      "        [132.2558]], device='mps:0')\n",
      "tensor([[  2.1093],\n",
      "        [ 75.4597],\n",
      "        [101.8738],\n",
      "        [146.7400]], device='mps:0')\n",
      "tensor([[109.0974],\n",
      "        [ 17.7261],\n",
      "        [164.2837],\n",
      "        [272.6621]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "dataset = CustomDataset(\"./datasets/non_linear.csv\")\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "val_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], torch.manual_seed(0))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "checkpoint = 1\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\" : \"CustomModel\",\n",
    "                \"epoch\" : epoch,\n",
    "                \"model_state_dict\" : model.state_dict(),\n",
    "                \"optimizer_state_dict\" : optimizer.state_dict(),\n",
    "                \"cost\" : cost,\n",
    "                \"description\" : f\"CustomModel Checkpoint-{checkpoint}\",\n",
    "            },\n",
    "            f\"./models/checkpoint-{checkpoint}.pt\",\n",
    "        )\n",
    "        checkpoint += 1\n",
    "        print(f\"epoch : {epoch+1:4d}, model : {list(model.parameters())}, cost : {cost:.3f}\")\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in val_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5181fc0",
   "metadata": {},
   "source": [
    "### 체크포인트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "71cbcb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel Checkpoint-6\n",
      "epoch : 7000, model : [Parameter containing:\n",
      "tensor([[ 3.1002, -1.7007]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.736\n",
      "epoch : 8000, model : [Parameter containing:\n",
      "tensor([[ 3.1007, -1.7009]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4839], device='mps:0', requires_grad=True)], cost : 0.732\n",
      "epoch : 9000, model : [Parameter containing:\n",
      "tensor([[ 3.1014, -1.7008]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.727\n",
      "epoch : 10000, model : [Parameter containing:\n",
      "tensor([[ 3.1009, -1.7008]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4840], device='mps:0', requires_grad=True)], cost : 0.723\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "dataset = CustomDataset(\"./datasets/non_linear.csv\")\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "val_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], torch.manual_seed(0))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "checkpoint = torch.load(\"./models/checkpoint-6.pt\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "checkpoint_epoch = checkpoint[\"epoch\"]\n",
    "checkpoint_description = checkpoint[\"description\"]\n",
    "print(checkpoint_description)\n",
    "\n",
    "\n",
    "for epoch in range(checkpoint_epoch+1, 10000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"epoch : {epoch+1:4d}, model : {list(model.parameters())}, cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1a43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91074911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df484a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4db08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
